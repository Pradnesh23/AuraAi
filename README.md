# AuraAI - AI-Powered Resume Ranking Service

AI-powered resume analysis that ranks candidates using **semantic analysis** and differentiates between **demonstrated skills** (proven experience) and **mentioned skills** (just listed).

---

## âœ¨ Features

- ğŸ“¤ **Multi-Format Upload** - ZIP, PDF, DOCX, or images (PNG/JPG/TIFF)
- ğŸ–¼ï¸ **OpenCV Preprocessing** - Denoise, deskew, enhance scanned images
- ğŸ“ **Smart OCR** - Tesseract for images, direct parsing for DOCX
- ğŸ¤– **LLM Ranking** - Ollama (llama3) for intelligent skill analysis
- âš–ï¸ **Skill Differentiation** - Weighted scoring for demonstrated vs mentioned skills

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph Client["ğŸ–¥ï¸ CLIENT"]
        UI[Web Browser]
    end

    subgraph Server["âš™ï¸ FASTAPI SERVER"]
        direction TB
        API[REST API]
        
        subgraph Processing["ğŸ“„ Document Processing"]
            direction LR
            DE[Document Extractor] --> IP[Image Processor] --> OCR[Tesseract OCR]
        end
        
        subgraph Intelligence["ğŸ¤– AI Layer"]
            direction LR
            RAG[RAG Service] --> LLM[LLM Ranker]
        end
    end

    subgraph External["ğŸ”Œ EXTERNAL"]
        direction LR
        OL[Ollama] --> EM[Embeddings]
        OL --> LM[LLM]
    end

    subgraph Storage["ğŸ’¾ STORAGE"]
        direction LR
        FS[Files] --> VS[Vectors]
    end

    UI ==>|HTTP Request| API
    API ==> Processing
    Processing ==> Intelligence
    Intelligence ==> External
    Processing ==> Storage

    linkStyle 0,1,2,3,4 stroke:#333,stroke-width:2px
```

---

## ğŸ‘¤ User Flow

```mermaid
flowchart TB
    subgraph Phase1["1ï¸âƒ£ UPLOAD"]
        direction LR
        A[ğŸ—‚ï¸ Select Files] --> B[ğŸ“ Drag & Drop]
        B --> C[â¬†ï¸ Upload]
    end

    subgraph Phase2["2ï¸âƒ£ PROCESS"]
        direction LR
        D[ğŸ“„ Extract Text] --> E[ğŸ”¢ Embeddings]
        E --> F[ğŸ’¾ Store]
    end

    subgraph Phase3["3ï¸âƒ£ ANALYZE"]
        direction LR
        G[ğŸ“ Enter Job Desc] --> H[ğŸ” Analyze]
        H --> I[ğŸ¤– AI Ranking]
    end

    subgraph Phase4["4ï¸âƒ£ RESULTS"]
        direction LR
        J[ğŸ“Š View Rankings] --> K[âœ… Demonstrated]
        K --> L[ğŸ“‹ Mentioned]
        L --> M[âŒ Missing]
    end

    Phase1 --> Phase2
    Phase2 --> Phase3
    Phase3 --> Phase4

    style Phase1 fill:#c8e6c9,stroke:#4caf50,stroke-width:2px
    style Phase2 fill:#fff9c4,stroke:#ffc107,stroke-width:2px
    style Phase3 fill:#bbdefb,stroke:#2196f3,stroke-width:2px
    style Phase4 fill:#f8bbd0,stroke:#e91e63,stroke-width:2px
```

---

## ğŸ”„ Data Pipeline

```mermaid
flowchart LR
    subgraph INPUT["ğŸ“¥ INPUT"]
        A[Files]
    end

    subgraph EXTRACT["ğŸ“‘ EXTRACT"]
        direction TB
        B[PDF] --> B1[Poppler]
        C[DOCX] --> C1[python-docx]
        D[Image] --> D1[OpenCV]
    end

    subgraph PROCESS["âš™ï¸ PROCESS"]
        direction TB
        E[Grayscale]
        E --> F[Denoise]
        F --> G[Deskew]
        G --> H[OCR]
    end

    subgraph STORE["ğŸ’¾ STORE"]
        direction TB
        I[Chunk Text]
        I --> J[Embed]
        J --> K[Vector DB]
    end

    subgraph ANALYZE["ğŸ¤– ANALYZE"]
        direction TB
        L[Parse JD]
        L --> M[Match Skills]
        M --> N[Score]
    end

    subgraph OUTPUT["ğŸ“Š OUTPUT"]
        O[Rankings]
    end

    INPUT ==> EXTRACT
    EXTRACT ==> PROCESS
    PROCESS ==> STORE
    STORE ==> ANALYZE
    ANALYZE ==> OUTPUT

    style INPUT fill:#ffeb3b,stroke:#f57f17,stroke-width:2px
    style EXTRACT fill:#ff9800,stroke:#e65100,stroke-width:2px
    style PROCESS fill:#03a9f4,stroke:#01579b,stroke-width:2px
    style STORE fill:#9c27b0,stroke:#4a148c,stroke-width:2px
    style ANALYZE fill:#e91e63,stroke:#880e4f,stroke-width:2px
    style OUTPUT fill:#4caf50,stroke:#1b5e20,stroke-width:2px
```

### Pipeline Stages

| Stage | Components | Output |
|-------|------------|--------|
| **Extract** | Poppler, python-docx, OpenCV | Raw content |
| **Process** | Grayscale â†’ Denoise â†’ Deskew â†’ OCR | Clean text |
| **Store** | Chunking â†’ Embeddings â†’ Vector DB | Searchable vectors |
| **Analyze** | JD Parsing â†’ Skill Matching â†’ Scoring | Match scores |

---

## âš–ï¸ Scoring Algorithm (Industry Standard ATS)

```mermaid
graph LR
    subgraph ATS["ATS Scoring"]
        A[Matched Skills] --> D[Base Score]
        B[Total Required] --> D
        C[Experience Years] -->|+5%/year| E[Bonus]
    end
    
    D --> F[Final Score %]
    E --> F
    
    style A fill:#4caf50
    style B fill:#2196f3
    style C fill:#ff9800
```

### Formula
```
Score = (Matched Skills / Total Required Skills) Ã— 100 + Experience Bonus
```

| Factor | Weight | Description |
|--------|--------|-------------|
| **Required Skills** | 1.0x | Must-have skills from JD |
| **Preferred Skills** | 0.5x | Nice-to-have skills |
| **Experience Bonus** | +5%/year | Max 15% bonus |

### Why This Formula?
- **Industry Standard**: Used by major ATS systems (Taleo, Workday, Greenhouse)
- **Fair & Objective**: No distinction between "demonstrated" vs "mentioned" (both can be fabricated)
- **Keyword-Based**: Matches how real ATS systems work

---

## ğŸš€ Quick Start

```powershell
# Prerequisites
ollama pull llama3
ollama pull nomic-embed-text

# Install
pip install -r requirements.txt

# Run
uvicorn main:app --reload
```

Access at **http://localhost:8000**

---

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Frontend UI |
| `/upload-resumes` | POST | Upload files |
| `/rank-candidates` | POST | Rank against JD |
| `/candidates/{id}` | GET | List candidates |

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| API | FastAPI |
| OCR | Tesseract |
| PDF | Poppler |
| Image | OpenCV |
| LLM | Ollama + llama3 |
| Embeddings | nomic-embed-text |

---

## ğŸ“ Project Structure

```
AuraAi/
â”œâ”€â”€ main.py              # API endpoints
â”œâ”€â”€ config.py            # Settings
â”œâ”€â”€ frontend/            # Web UI (HTML/CSS/JS)
â”œâ”€â”€ models/schemas.py    # Pydantic models
â””â”€â”€ services/
    â”œâ”€â”€ document_extractor.py
    â”œâ”€â”€ image_processor.py
    â”œâ”€â”€ rag_service.py
    â””â”€â”€ llm_ranker.py
```

---

## ğŸ“š Documentation

- **Swagger**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
